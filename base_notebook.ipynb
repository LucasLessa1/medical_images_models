{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skin Lesions Dataset Description\n",
    "\n",
    "The dataset comprises various types of skin lesions, each falling under specific categories:\n",
    "\n",
    "- **Actinic Keratoses and Intraepithelial Carcinoma / Bowen's Disease (AKIEC)**\n",
    "- **Basal Cell Carcinoma (BCC)**\n",
    "- **Benign Keratosis-like Lesions**:\n",
    "  - *Solar Lentigines*\n",
    "  - *Seborrheic Keratoses*\n",
    "  - *Lichen-Planus like Keratoses (BKL)*\n",
    "- **Dermatofibroma (DF)**\n",
    "- **Melanoma (MEL)**\n",
    "- **Melanocytic Nevi (NV)**\n",
    "- **Vascular Lesions**:\n",
    "  - *Angiomas*\n",
    "  - *Angiokeratomas*\n",
    "  - *Pyogenic Granulomas*\n",
    "  - *Hemorrhage (VASC)*\n",
    "\n",
    "**Diagnosis Confirmation:**\n",
    "\n",
    "- Over 50% of lesions in this dataset are confirmed through **histopathology (Histo)**, serving as the ground truth for these cases.\n",
    "- For the remaining cases, confirmation methods include:\n",
    "  - *Follow-up examination (Follow_Up)*\n",
    "  - *Expert Consensus (Consensus)*\n",
    "  - *Confirmation by In-Vivo Confocal Microscopy (Confocal)*\n",
    "\n",
    "Each lesion might have multiple associated images, allowing for tracking via the `lesion_id` column within the `HAM10000_metadata` file.\n",
    "\n",
    "This diverse dataset contains various types of skin lesions, each categorized and confirmed through different diagnostic approaches, contributing to a comprehensive resource for research and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_dict = {\n",
    "#     'akiec': \"Actinic Keratoses and Intraepithelial Carcinoma / Bowen's Disease (AKIEC)\",\n",
    "#     'bcc': \"Basal Cell Carcinoma (BCC)\",\n",
    "#     'bkl': \"Benign Keratosis-like Lesions\",\n",
    "#     'df': \"Dermatofibroma (DF)\",\n",
    "#     'mel': \"Melanoma (MEL)\",\n",
    "#     'nv': \"Melanocytic Nevi (NV)\",\n",
    "#     'vasc': \"Vascular Lesions\",\n",
    "#     'histo': \"Confirmed through Histopathology (Histo)\",\n",
    "#     'follow_up': \"Follow-up examination (Follow_Up)\",\n",
    "#     'consensus': \"Expert Consensus (Consensus)\",\n",
    "#     'confocal': \"Confirmation by In-Vivo Confocal Microscopy (Confocal)\"\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import glob\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import PIL \n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tool_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, labels are initially considered as categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the images are organized in the folders of each label, the following flag must be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_folder_sep = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_folder_sep:\n",
    "    base_path = 'C:/Users/lucas/OneDrive - unb.br/Documents/UnB/Semestres-ENE/TCC/COVID_Dataset_original'\n",
    "else:\n",
    "    base_path = 'C:/Users/lucas/OneDrive - unb.br/Documents/UnB/Semestres-ENE/TCC/The HAM10000 dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nv - 671\n",
      "mel - 112\n",
      "bkl - 110\n",
      "bcc - 52\n",
      "akiec - 33\n",
      "vasc - 15\n",
      "df - 12\n"
     ]
    }
   ],
   "source": [
    "if flag_folder_sep :\n",
    "    label_column = 'label'\n",
    "    train_df, test_df, val_df  = make_dataset_by_folder(base_path=base_path, label_column=label_column)\n",
    "\n",
    "else:\n",
    "    \n",
    "    path_train_df = f'{base_path}/HAM10000_metadata'\n",
    "    path_test_df = f'{base_path}/test.csv'\n",
    "    \n",
    "    path_train = f\"{base_path}/treino\"\n",
    "    path_test = f\"{base_path}/test\"\n",
    "    \n",
    "    paths_image = [path_train, path_test]\n",
    "    paths_df = [path_train_df, path_test_df]\n",
    "    label_column = 'dx'\n",
    "    \n",
    "    train_df, test_df, val_df = make_dataset_by_df(paths_image, paths_df, label_column=label_column)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = check_images_existence(train_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest pixel value: 0\n",
      "Largest pixel value: 255\n",
      "Total images processed: 9010\n",
      "Channel Statistics:\n",
      "Channel 'R':\n",
      "  - Average: 194.68187054753977\n",
      "  - Standard Deviation: 22.791095609509448\n",
      "Channel 'G':\n",
      "  - Average: 139.18874363628888\n",
      "  - Standard Deviation: 30.127021221194617\n",
      "Channel 'B':\n",
      "  - Average: 145.4035463994738\n",
      "  - Standard Deviation: 33.85997329924692\n"
     ]
    }
   ],
   "source": [
    "image_analysis_train = image_analysis(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 9010\n",
      "Number of unique labels: 7\n",
      "Label 'nv' has 6034 images.\n",
      "Label 'mel' has 1001 images.\n",
      "Label 'bkl' has 989 images.\n",
      "Label 'bcc' has 462 images.\n",
      "Label 'akiec' has 294 images.\n",
      "Label 'vasc' has 127 images.\n",
      "Label 'df' has 103 images.\n",
      "Average image shape - Height: 450.0, Width: 600.0\n",
      "Number of images with shape smaller than (800, 800): 9010\n"
     ]
    }
   ],
   "source": [
    "dict_train_qntd = get_label_counts_and_print(train_df, label_column=label_column)\n",
    "shapes_train = analyze_image_shapes(train_df, min_shape=(800, 800), path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nv': 6034,\n",
       " 'mel': 1001,\n",
       " 'bkl': 989,\n",
       " 'bcc': 462,\n",
       " 'akiec': 294,\n",
       " 'vasc': 127,\n",
       " 'df': 103}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_train_qntd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = check_images_existence(test_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest pixel value: 0\n",
      "Largest pixel value: 255\n",
      "Total images processed: 1511\n",
      "Channel Statistics:\n",
      "Channel 'R':\n",
      "  - Average: 193.96235187636344\n",
      "  - Standard Deviation: 24.606448726550262\n",
      "Channel 'G':\n",
      "  - Average: 141.7550379243572\n",
      "  - Standard Deviation: 31.9625774054364\n",
      "Channel 'B':\n",
      "  - Average: 147.87214814814814\n",
      "  - Standard Deviation: 35.78649271231254\n"
     ]
    }
   ],
   "source": [
    "image_analysis_test = image_analysis(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_qntd = get_label_counts_and_print(test_df, label_column=label_column)\n",
    "shapes_test = analyze_image_shapes(test_df, min_shape=(300, 300), path_column='path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = check_images_existence(val_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_analysis_val = image_analysis(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_val_qntd = get_label_counts_and_print(val_df, label_column=label_column)\n",
    "shapes_val = analyze_image_shapes(val_df, min_shape=(461, 601), path_column='path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passar de categorial para binário "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pesos para a loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorial to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = labels2dict(train_df, label_column)\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label, test_label, val_label = dflabel2number([train_df, test_df, val_df], labels_dict, label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(labels_dict) == 1:\n",
    "    weights = calculate_weights(train_df, labels_dict, dict_train_qntd)\n",
    "    weights = max(weights)\n",
    "else:\n",
    "    weights = calculate_weights(train_df, labels_dict, dict_train_qntd)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CT_Dataset(Dataset):\n",
    "    def __init__(self, img_path, img_labels, channels, img_transforms=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_labels = torch.Tensor(img_labels)\n",
    "        if channels == 1:\n",
    "            self.transforms = transforms.Compose([transforms.Grayscale(),\n",
    "                                                #   transforms.Resize((250, 250)),\n",
    "                                                  transforms.ToTensor()])\n",
    "        elif channels == 3:\n",
    "            self.transforms = transforms.Compose([#transforms.Resize((250, 250)),\n",
    "                                                  transforms.ToTensor()])\n",
    "        else:\n",
    "            self.transforms = img_transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        cur_path = self.img_path[index]\n",
    "        cur_img = PIL.Image.open(cur_path).convert('RGB')\n",
    "        cur_img = self.transforms(cur_img)\n",
    "\n",
    "        return cur_img, self.img_labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current GPU memory usage:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n",
    "print(\"Max GPU memory usage:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 124\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mean_R = image_analysis_val['channel_statistics']['R']['average']\n",
    "    mean_G = image_analysis_val['channel_statistics']['G']['average']\n",
    "    mean_B = image_analysis_val['channel_statistics']['B']['average']\n",
    "    channels = 1 if mean_R == mean_G == mean_B else 3\n",
    "    \n",
    "except KeyError:\n",
    "    channels = image_analysis_val['channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CT_Dataset(img_path=np.array(train_df['path']), img_labels=np.array(train_label), channels=channels)\n",
    "val_dataset = CT_Dataset(img_path=np.array(val_df['path']), img_labels=np.array(val_label), channels=channels)\n",
    "test_dataset = CT_Dataset(img_path=np.array(test_df['path']), img_labels=np.array(test_label), channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "Epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "# model_kernel = VGG16(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = ResNet50(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = ResNet101(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = EfficientNetB0(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = EfficientNetB4(num_classes=len(labels_dict), input_channels=channels)\n",
    "model_kernel = EfficientNetB7(num_classes=len(labels_dict), input_channels=channels)\n",
    "\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(model_kernel, device, weights, labels_dict, train_dataset, val_dataset, test_dataset, batch_size= batch_size, epochs=Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.loader()\n",
    "trainer.loss_function()\n",
    "trainer.optimizer_step()\n",
    "print(\"Training Start:\")\n",
    "for epoch in range(Epochs):\n",
    "    trainer.model.train()\n",
    "\n",
    "    trainer.train_loss = 0\n",
    "    trainer.train_acc = 0\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.validate()\n",
    "    history = trainer.loss_acc()\n",
    "\n",
    "\n",
    "    print(f\"Epoch:{epoch + 1} / {Epochs}, lr: {trainer.optimizer.param_groups[0]['lr']:.5f} train loss:{trainer.train_loss:.5f}, train acc: {trainer.train_acc:.5f}, valid loss:{trainer.val_loss:.5f}, valid acc:{trainer.val_acc:.5f}\")\n",
    "        \n",
    "    # Update the best model if validation loss is the lowest so far\n",
    "    if trainer.val_loss < trainer.best_val_loss:\n",
    "        trainer.best_val_loss = trainer.val_loss\n",
    "        trainer.best_model_state = trainer.model.state_dict()\n",
    "\n",
    "    print(f'The best val loss is {trainer.best_val_loss}.\\n')\n",
    "    \n",
    "    # Load the best model state\n",
    "    if trainer.best_model_state is not None:\n",
    "        trainer.model.load_state_dict(trainer.best_model_state)\n",
    "    model = trainer.model\n",
    "    \n",
    "trainer.test()\n",
    "metrics_df = trainer.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = trainer.metrics()\n",
    "metrics_df = metrics_df.applymap(lambda x: str(x).replace('.', ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_metrics import *                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_folder_sep:\n",
    "    results_path = f\"C:/Users/Lucas/medical_images_models/results_COVID/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}\"\n",
    "\n",
    "else:\n",
    "    results_path = f\"C:/Users/Lucas/medical_images_models/results_HAM/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f'results_HAM/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df[\"Accuracy\"][0]}.pth'\n",
    "\n",
    "metrics_df.to_csv(f'{results_path}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, path=results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Images - True Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_labels_dict = {value: key for key, value in labels_dict.items()}\n",
    "inverted_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_pred_true(model, test_dataset, device, inverted_labels_dict, num_images_to_plot=20, plot_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{results_path}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
