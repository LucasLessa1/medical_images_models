{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import glob\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import PIL \n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tool_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, labels are initially considered as categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the images are organized in the folders of each label, the following flag must be True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grande Osmar, deixa a flag como True mesmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_folder_sep = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_folder_sep:\n",
    "    base_path = input(\"Qual é o caminho do dataset?\")\n",
    "    # base_path = 'C:/Users/lucas/OneDrive - unb.br/Documents/UnB/Semestres-ENE/TCC/COVID_Dataset_original'\n",
    "    results_path = input(\"Qual será o caminho para os resultados?\")\n",
    "    # results_path = f\"C:/Users/Lucas/medical_images_models/results_COVID\"\n",
    "else:\n",
    "    # base_path = 'C:/Users/lucas/OneDrive - unb.br/Documents/UnB/Semestres-ENE/TCC/The HAM10000 dataset'\n",
    "    # results_path = f\"C:/Users/Lucas/medical_images_models/results_HAM\"\n",
    "    base_path = input(\"Qual é o caminho do dataset?\")\n",
    "    results_path = input(\"Qual será o caminho para os resultados?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nv - 671\n",
      "mel - 112\n",
      "bkl - 110\n",
      "bcc - 52\n",
      "akiec - 33\n",
      "vasc - 15\n",
      "df - 12\n"
     ]
    }
   ],
   "source": [
    "if flag_folder_sep :\n",
    "    label_column = 'label'\n",
    "    train_df, test_df, val_df  = make_dataset_by_folder(base_path=base_path, label_column=label_column)\n",
    "\n",
    "else:\n",
    "    \n",
    "    path_train_df = f'{base_path}/HAM10000_metadata'\n",
    "    path_test_df = f'{base_path}/test.csv'\n",
    "    \n",
    "    path_train = f\"{base_path}/treino\"\n",
    "    path_test = f\"{base_path}/test\"\n",
    "    \n",
    "    paths_image = [path_train, path_test]\n",
    "    paths_df = [path_train_df, path_test_df]\n",
    "    label_column = 'dx'\n",
    "    \n",
    "    train_df, test_df, val_df = make_dataset_by_df(paths_image, paths_df, label_column=label_column)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = check_images_existence(train_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_analysis_train \u001b[38;5;241m=\u001b[39m \u001b[43mimage_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Codigos_VS\\medical_images_models\\tool_preprocessing.py:152\u001b[0m, in \u001b[0;36mimage_analysis\u001b[1;34m(dataframe, path_column)\u001b[0m\n\u001b[0;32m    149\u001b[0m image_path \u001b[38;5;241m=\u001b[39m row[path_column]\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image_path\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# Read the image using imageio\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# Check if the image is grayscale or RGB\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# Grayscale image\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py:265\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperhaps you mean \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpilmode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    262\u001b[0m     )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Get reader and read first\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m reader \u001b[38;5;241m=\u001b[39m read(uri, \u001b[38;5;28mformat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mget_data(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py:178\u001b[0m, in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m formats[\u001b[38;5;28mformat\u001b[39m]\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mformats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_read_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     modename \u001b[38;5;241m=\u001b[39m MODENAMES\u001b[38;5;241m.\u001b[39mget(mode, mode)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\format.py:689\u001b[0m, in \u001b[0;36mFormatManager.search_read_format\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;66;03m# Select the first that can\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m selected_formats:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcan_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    690\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# If no format could read it, it could be that file has no or\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# the wrong extension. We ask all formats again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\format.py:192\u001b[0m, in \u001b[0;36mFormat.can_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcan_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;124;03m\"\"\" can_read(request)\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    Get whether this format can read data from the specified uri.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\plugins\\pillow.py:107\u001b[0m, in \u001b[0;36mPillowFormat._can_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    105\u001b[0m factory, accept \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mOPEN[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplugin_id]\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirstbytes\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m accept(request\u001b[38;5;241m.\u001b[39mfirstbytes):\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py:442\u001b[0m, in \u001b[0;36mRequest.firstbytes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03m\"\"\" The first 256 bytes of the file. These can be used to\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03mparse the header to determine the file-format.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_firstbytes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_first_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_firstbytes\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py:451\u001b[0m, in \u001b[0;36mRequest._read_first_bytes\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# Prepare\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m         f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename):  \u001b[38;5;66;03m# A directory, e.g. for DICOM\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py:333\u001b[0m, in \u001b[0;36mRequest.get_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uri_type \u001b[38;5;241m==\u001b[39m URI_ZIPPED:\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m# Get the correct filename\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     filename, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename_zip\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_analysis_train = image_analysis(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 9010\n",
      "Number of unique labels: 7\n",
      "Label 'nv' has 6034 images.\n",
      "Label 'mel' has 1001 images.\n",
      "Label 'bkl' has 989 images.\n",
      "Label 'bcc' has 462 images.\n",
      "Label 'akiec' has 294 images.\n",
      "Label 'vasc' has 127 images.\n",
      "Label 'df' has 103 images.\n",
      "Average image shape - Height: 450.0, Width: 600.0\n",
      "Number of images with shape smaller than (800, 800): 9010\n"
     ]
    }
   ],
   "source": [
    "dict_train_qntd = get_label_counts_and_print(train_df, label_column=label_column)\n",
    "shapes_train = analyze_image_shapes(train_df, min_shape=(800, 800), path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nv': 6034,\n",
       " 'mel': 1001,\n",
       " 'bkl': 989,\n",
       " 'bcc': 462,\n",
       " 'akiec': 294,\n",
       " 'vasc': 127,\n",
       " 'df': 103}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_train_qntd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = check_images_existence(test_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest pixel value: 0\n",
      "Largest pixel value: 255\n",
      "Total images processed: 1511\n",
      "Channel Statistics:\n",
      "Channel 'R':\n",
      "  - Average: 193.96235187636344\n",
      "  - Standard Deviation: 24.606448726550262\n",
      "Channel 'G':\n",
      "  - Average: 141.7550379243572\n",
      "  - Standard Deviation: 31.9625774054364\n",
      "Channel 'B':\n",
      "  - Average: 147.87214814814814\n",
      "  - Standard Deviation: 35.78649271231254\n"
     ]
    }
   ],
   "source": [
    "image_analysis_test = image_analysis(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_qntd = get_label_counts_and_print(test_df, label_column=label_column)\n",
    "shapes_test = analyze_image_shapes(test_df, min_shape=(300, 300), path_column='path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = check_images_existence(val_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_analysis_val = image_analysis(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_val_qntd = get_label_counts_and_print(val_df, label_column=label_column)\n",
    "shapes_val = analyze_image_shapes(val_df, min_shape=(461, 601), path_column='path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passar de categorial para binário "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pesos para a loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorial to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = labels2dict(train_df, label_column)\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label, test_label, val_label = dflabel2number([train_df, test_df, val_df], labels_dict, label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(labels_dict) == 1:\n",
    "    weights = calculate_weights(train_df, labels_dict, dict_train_qntd)\n",
    "    weights = max(weights)\n",
    "else:\n",
    "    weights = calculate_weights(train_df, labels_dict, dict_train_qntd)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CT_Dataset(Dataset):\n",
    "    def __init__(self, img_path, img_labels, channels, img_transforms=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_labels = torch.Tensor(img_labels)\n",
    "        if channels == 1:\n",
    "            self.transforms = transforms.Compose([transforms.Grayscale(),\n",
    "                                                #   transforms.Resize((250, 250)),\n",
    "                                                  transforms.ToTensor()])\n",
    "        elif channels == 3:\n",
    "            self.transforms = transforms.Compose([#transforms.Resize((250, 250)),\n",
    "                                                  transforms.ToTensor()])\n",
    "        else:\n",
    "            self.transforms = img_transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        cur_path = self.img_path[index]\n",
    "        cur_img = PIL.Image.open(cur_path).convert('RGB')\n",
    "        cur_img = self.transforms(cur_img)\n",
    "\n",
    "        return cur_img, self.img_labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current GPU memory usage:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n",
    "print(\"Max GPU memory usage:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 124\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mean_R = image_analysis_val['channel_statistics']['R']['average']\n",
    "    mean_G = image_analysis_val['channel_statistics']['G']['average']\n",
    "    mean_B = image_analysis_val['channel_statistics']['B']['average']\n",
    "    channels = 1 if mean_R == mean_G == mean_B else 3\n",
    "    \n",
    "except KeyError:\n",
    "    channels = image_analysis_val['channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CT_Dataset(img_path=np.array(train_df['path']), img_labels=np.array(train_label), channels=channels)\n",
    "val_dataset = CT_Dataset(img_path=np.array(val_df['path']), img_labels=np.array(val_label), channels=channels)\n",
    "test_dataset = CT_Dataset(img_path=np.array(test_df['path']), img_labels=np.array(test_label), channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "Epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "# model_kernel = VGG16(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = ResNet50(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = ResNet101(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = EfficientNetB0(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = EfficientNetB4(num_classes=len(labels_dict), input_channels=channels)\n",
    "model_kernel = EfficientNetB7(num_classes=len(labels_dict), input_channels=channels)\n",
    "\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(model_kernel, device, weights, labels_dict, train_dataset, val_dataset, test_dataset, batch_size= batch_size, epochs=Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.loader()\n",
    "trainer.loss_function()\n",
    "trainer.optimizer_step()\n",
    "print(\"Training Start:\")\n",
    "for epoch in range(Epochs):\n",
    "    trainer.model.train()\n",
    "\n",
    "    trainer.train_loss = 0\n",
    "    trainer.train_acc = 0\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.validate()\n",
    "    history = trainer.loss_acc()\n",
    "\n",
    "\n",
    "    print(f\"Epoch:{epoch + 1} / {Epochs}, lr: {trainer.optimizer.param_groups[0]['lr']:.5f} train loss:{trainer.train_loss:.5f}, train acc: {trainer.train_acc:.5f}, valid loss:{trainer.val_loss:.5f}, valid acc:{trainer.val_acc:.5f}\")\n",
    "        \n",
    "    # Update the best model if validation loss is the lowest so far\n",
    "    if trainer.val_loss < trainer.best_val_loss:\n",
    "        trainer.best_val_loss = trainer.val_loss\n",
    "        trainer.best_model_state = trainer.model.state_dict()\n",
    "\n",
    "    print(f'The best val loss is {trainer.best_val_loss}.\\n')\n",
    "    \n",
    "    # Load the best model state\n",
    "    if trainer.best_model_state is not None:\n",
    "        trainer.model.load_state_dict(trainer.best_model_state)\n",
    "    model = trainer.model\n",
    "    \n",
    "trainer.test()\n",
    "metrics_df = trainer.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = trainer.metrics()\n",
    "metrics_df = metrics_df.applymap(lambda x: str(x).replace('.', ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_metrics import *                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if flag_folder_sep:\n",
    "#     results_path = f\"C:/Users/Lucas/medical_images_models/results_COVID/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}\"\n",
    "\n",
    "# else:\n",
    "#     results_path = f\"C:/Users/Lucas/medical_images_models/results_HAM/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(f\"{results_path}/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, path=results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Images - True Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_labels_dict = {value: key for key, value in labels_dict.items()}\n",
    "inverted_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_pred_true(model, test_dataset, device, inverted_labels_dict, num_images_to_plot=20, plot_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{results_path}/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
