{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flake8 in c:\\users\\lucas\\appdata\\local\\anaconda3\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in c:\\users\\lucas\\appdata\\local\\anaconda3\\lib\\site-packages (from flake8) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.11.0,>=2.10.0 in c:\\users\\lucas\\appdata\\local\\anaconda3\\lib\\site-packages (from flake8) (2.10.0)\n",
      "Requirement already satisfied: pyflakes<3.1.0,>=3.0.0 in c:\\users\\lucas\\appdata\\local\\anaconda3\\lib\\site-packages (from flake8) (3.0.1)\n",
      "Requirement already satisfied: pycodestyle in c:\\users\\lucas\\appdata\\local\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: pycodestyle_magic in c:\\users\\lucas\\appdata\\local\\anaconda3\\lib\\site-packages (0.5)\n",
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "!pip install flake8\n",
    "!pip install pycodestyle pycodestyle_magic\n",
    "import pycodestyle\n",
    "import flake8\n",
    "%load_ext pycodestyle_magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300:80: E501 line too long (140 > 79 characters)\n",
      "306:80: E501 line too long (95 > 79 characters)\n",
      "311:80: E501 line too long (109 > 79 characters)\n",
      "332:1: W293 blank line contains whitespace\n",
      "366:29: E225 missing whitespace around operator\n",
      "556:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple, Dict, Union\n",
    "\n",
    "\n",
    "def build_dataset(folder_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a dataset from images stored in subdirectories.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): Path to the folder containing\n",
    "    subdirectories with images.\n",
    "\n",
    "    Returns:\n",
    "    - dataset (pd.DataFrame): DataFrame containing image\n",
    "    details (name, path, label).\n",
    "    \"\"\"\n",
    "    data = {'name': [], 'path': [], 'label': []}\n",
    "\n",
    "    # Iterate through subdirectories (labels)\n",
    "    for label in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label)\n",
    "\n",
    "        # Check if the item is a directory\n",
    "        if os.path.isdir(label_path):\n",
    "            # Iterate through image files in the subdirectory\n",
    "            for image in os.listdir(label_path):\n",
    "                image_path = os.path.join(label_path, image)\n",
    "\n",
    "                # Check if the item is a file and is an image file\n",
    "                if (os.path.isfile(image_path) and\n",
    "                   image.lower().endswith(('.png', '.jpg', '.jpeg'))):\n",
    "                    # Append image details to the dataset\n",
    "                    data['name'].append(image)\n",
    "                    data['path'].append(image_path)\n",
    "                    data['label'].append(label)\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    dataset = pd.DataFrame(data)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_dataset_by_folder(base_path: str,\n",
    "                           label_column: str\n",
    "                           ) -> Union[\n",
    "                            pd.DataFrame,\n",
    "                            pd.DataFrame,\n",
    "                            pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create a dataset by splitting images into training, testing,\n",
    "    and validation sets based on folders.\n",
    "\n",
    "    Args:\n",
    "    - base_path (str): Path to the base folder containing subdirectories\n",
    "    with images.\n",
    "    - label_column (str): Name of the column containing labels in\n",
    "    the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of DataFrames: Three DataFrames representing the training,\n",
    "    testing, and validation sets.\n",
    "    \"\"\"\n",
    "    dataset = build_dataset(base_path)\n",
    "    train_df, test_df, val_df = split_dataset_by_label(\n",
    "        dataset,\n",
    "        label_column=label_column,\n",
    "        train_size=0.8,\n",
    "        test_size=0.1,\n",
    "        val_size=0.1)\n",
    "    compare_label_counts(dataset,\n",
    "                         train_df,\n",
    "                         desired_proportion=0.8)\n",
    "    compare_label_counts(dataset,\n",
    "                         test_df,\n",
    "                         desired_proportion=0.1)\n",
    "    compare_label_counts(dataset,\n",
    "                         val_df,\n",
    "                         desired_proportion=0.1)\n",
    "\n",
    "    return train_df, test_df, val_df\n",
    "\n",
    "\n",
    "def make_dataset_by_df(paths_image: Tuple[str, str],\n",
    "                       paths_df: Tuple[str, str],\n",
    "                       label_column: str\n",
    "                       ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create a dataset by combining image paths with DataFrame paths.\n",
    "\n",
    "    Args:\n",
    "    - paths_image (Tuple[str, str]): Tuple containing paths\n",
    "    to image folders for training and testing.\n",
    "    - paths_df (Tuple[str, str]): Tuple containing paths\n",
    "    to DataFrames for training and testing.\n",
    "    - label_column (str): Name of the column containing\n",
    "    labels in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of DataFrames: Three DataFrames representing the training,\n",
    "    testing, and validation sets.\n",
    "    \"\"\"\n",
    "    train_df = pd.read_csv(paths_df[0])\n",
    "    train_df = add_image_paths_to_dataframe(train_df,\n",
    "                                            paths_image[0],\n",
    "                                            column_name='image_id')\n",
    "\n",
    "    test_df = pd.read_csv(paths_df[1])\n",
    "    test_df = add_image_paths_to_dataframe(test_df,\n",
    "                                           paths_image[1],\n",
    "                                           column_name='image_id')\n",
    "\n",
    "    train_df, val_df = split_dataset_by_label(train_df,\n",
    "                                              label_column=label_column,\n",
    "                                              train_size=0.9,\n",
    "                                              test_size=0,\n",
    "                                              val_size=0.1,\n",
    "                                              return_test=False)\n",
    "\n",
    "    return train_df, test_df, val_df\n",
    "\n",
    "\n",
    "def split_dataset_by_label(dataframe: pd.DataFrame,\n",
    "                           train_size: float,\n",
    "                           test_size: float,\n",
    "                           val_size: float,\n",
    "                           label_column: str = \"label\",\n",
    "                           return_test: bool = True\n",
    "                           ) -> Union[\n",
    "                               pd.DataFrame,\n",
    "                               pd.DataFrame,\n",
    "                               pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training, testing, and validation sets\n",
    "    based on labels.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing the dataset.\n",
    "    - train_size (float): Proportion of the dataset to include\n",
    "    in the training set.\n",
    "    - test_size (float): Proportion of the dataset to include\n",
    "    in the testing set.\n",
    "    - val_size (float): Proportion of the dataset to include\n",
    "    in the validation set.\n",
    "    - label_column (str, optional): Name of the column containing\n",
    "    labels in the dataset (default: \"label\").\n",
    "    - return_test (bool, optional): Whether to return the testing\n",
    "    set (default: True).\n",
    "\n",
    "    Returns:\n",
    "    - Union of DataFrames: Three DataFrames representing the training,\n",
    "    testing, and validation sets.\n",
    "    \"\"\"\n",
    "    # Shuffle the dataframe\n",
    "    shuffled_data = (dataframe.sample(frac=1, random_state=42)\n",
    "                     .reset_index(drop=True))\n",
    "\n",
    "    # Calculate the counts of each label\n",
    "    label_counts = shuffled_data[label_column].value_counts()\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "    val_data = pd.DataFrame()\n",
    "\n",
    "    # Iterate through unique labels\n",
    "    for label in label_counts.index:\n",
    "        label_data = shuffled_data[shuffled_data[label_column] == label]\n",
    "        train, test_val = train_test_split(label_data,\n",
    "                                           test_size=(1 - train_size),\n",
    "                                           random_state=42)\n",
    "\n",
    "        if return_test:\n",
    "            test, val = train_test_split(test_val,\n",
    "                                         test_size=(val_size /\n",
    "                                                    (val_size + test_size)),\n",
    "                                         random_state=42)\n",
    "            test_data = pd.concat([test_data, test])\n",
    "\n",
    "            if val_size > 0:\n",
    "                val_data = pd.concat([val_data, val])\n",
    "        else:\n",
    "\n",
    "            if val_size > 0:\n",
    "                val_size_label = int(len(test_val) *\n",
    "                                     (val_size / (val_size + test_size)))\n",
    "                val_data = pd.concat([val_data,\n",
    "                                      test_val.sample(n=val_size_label,\n",
    "                                                      random_state=42)])\n",
    "\n",
    "        train_data = pd.concat([train_data, train])\n",
    "\n",
    "    if return_test and val_size > 0:\n",
    "        return train_data, test_data, val_data\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "\n",
    "def compare_label_counts(original_df: pd.DataFrame,\n",
    "                         train_df: pd.DataFrame,\n",
    "                         desired_proportion: float,\n",
    "                         label_column: str = 'label') -> None:\n",
    "    \"\"\"\n",
    "    Compare label counts between original and training datasets.\n",
    "\n",
    "    Args:\n",
    "    - original_df (pd.DataFrame): Original DataFrame\n",
    "    containing the dataset.\n",
    "    - train_df (pd.DataFrame): DataFrame representing\n",
    "    the training set.\n",
    "    - desired_proportion (float): Desired proportion\n",
    "    of each label in the training set.\n",
    "    - label_column (str, optional): Name of the column\n",
    "    containing labels in the dataset (default: 'label').\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    label_counts_original = original_df[label_column].value_counts()\n",
    "\n",
    "    for label, _ in label_counts_original.items():\n",
    "        expected_count = int(len(original_df.loc[\n",
    "            original_df[label_column] == label]) * desired_proportion)\n",
    "        actual_count = len(train_df.loc[train_df[label_column] == label])\n",
    "\n",
    "        if expected_count == actual_count:\n",
    "            print(\"Is equal\")\n",
    "        else:\n",
    "            print(f\"Label '{label}' is not equal. Expected\"\n",
    "                  f\" - {expected_count}, Actual - {actual_count}\")\n",
    "\n",
    "\n",
    "def add_image_paths_to_dataframe(dataframe: pd.DataFrame,\n",
    "                                 folder_path: str,\n",
    "                                 column_name: str\n",
    "                                 ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add image paths to a DataFrame based on image IDs and a folder path.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing image IDs.\n",
    "    - folder_path (str): Path to the folder containing the images.\n",
    "    - column_name (str): Name of the column containing image IDs\n",
    "    in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - dataframe (pd.DataFrame): DataFrame with added 'path' column\n",
    "    containing image paths.\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "\n",
    "    # Get the list of image files in the folder\n",
    "    image_files = os.listdir(folder_path)\n",
    "    image_files = [f for f in image_files if f.endswith('.jpg')]\n",
    "\n",
    "    # Create a dictionary mapping image_id to image file names in the folder\n",
    "    image_id_to_file = {file.split('.')[0]: file for file in image_files}\n",
    "\n",
    "    # Iterate through 'image_id' column in the DataFrame\n",
    "    for image_id in dataframe[column_name]:\n",
    "        # Check if the image_id exists in the dictionary mapping\n",
    "        if image_id in image_id_to_file:\n",
    "            image_file = os.path.join(folder_path, image_id_to_file[image_id])\n",
    "            image_paths.append(image_file)\n",
    "        else:\n",
    "            image_paths.append(None)  # If image doesn't exist, insert None\n",
    "\n",
    "    # Add a new column 'path' with the image paths to the DataFrame\n",
    "    dataframe['path'] = image_paths\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def get_label_counts_and_print(dataframe: pd.DataFrame,\n",
    "                               label_column: str\n",
    "                               ) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Get the counts of each label in the dataframe and print the results.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing the dataset.\n",
    "    - label_column (str): Name of the column containing labels in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - label_counts (Dict[str, int]): Dictionary containing label counts.\n",
    "    \"\"\"\n",
    "    total_images = len(dataframe)  # Total number of images in the dataframe\n",
    "    label_counts = dataframe[label_column].value_counts().to_dict()\n",
    "\n",
    "    print(f\"Total number of images: {total_images}\")\n",
    "    print(f\"Number of unique labels: {len(label_counts)}\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Label '{label}' has {count} images.\")\n",
    "\n",
    "    return label_counts\n",
    "\n",
    "\n",
    "def calculate_image_statistics(dataframe: pd.DataFrame, path_column: str = 'path') -> Tuple[int, int, Dict[str, List[Tuple[float, float]]]]:\n",
    "    \"\"\"\n",
    "    Calculate statistics for the images in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing image paths.\n",
    "    - path_column (str, optional): Name of the column containing image paths (default: 'path').\n",
    "\n",
    "    Returns:\n",
    "    - smallest_pixel (int): Smallest pixel value found in the images.\n",
    "    - largest_pixel (int): Largest pixel value found in the images.\n",
    "    - channel_values (Dict[str, List[Tuple[float, float]]]): Channel-wise mean and standard deviation values.\n",
    "    \"\"\"\n",
    "    smallest_pixel = float('inf')\n",
    "    largest_pixel = 0\n",
    "    total_images = 0\n",
    "    channel_values = {'R': [], 'G': [], 'B': []}\n",
    "    # Iterate through each image in the dataframe\n",
    "    for _, row in dataframe.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Read the image using imageio\n",
    "            image = imageio.imread(image_path)\n",
    "\n",
    "            # Check if the image is grayscale or RGB\n",
    "            if len(image.shape) == 2:  # Grayscale image\n",
    "                min_pixel = np.min(image)\n",
    "                max_pixel = np.max(image)\n",
    "                smallest_pixel = min(smallest_pixel, min_pixel)\n",
    "                largest_pixel = max(largest_pixel, max_pixel)\n",
    "                total_images += 1\n",
    "                continue\n",
    "   \n",
    "            if len(image.shape) == 3 and image.shape[2] == 4:  # RGBA image\n",
    "                image = image[:, :, :3]  # Remove alpha channel\n",
    "\n",
    "            # Check for smallest and largest pixel value\n",
    "            min_pixel = np.min(image)\n",
    "            max_pixel = np.max(image)\n",
    "            smallest_pixel = min(smallest_pixel, min_pixel)\n",
    "            largest_pixel = max(largest_pixel, max_pixel)\n",
    "\n",
    "            # Extract channel-wise values\n",
    "            channels = np.dsplit(image, image.shape[-1])\n",
    "            for i, channel in enumerate(channels):\n",
    "                mean_val = np.mean(channel)\n",
    "                std_val = np.std(channel)\n",
    "\n",
    "                if i == 0:\n",
    "                    channel_label = 'R'\n",
    "                elif i == 1:\n",
    "                    channel_label = 'G'\n",
    "                else:\n",
    "                    channel_label = 'B'\n",
    "\n",
    "                channel_values[channel_label].append((mean_val, std_val))\n",
    "\n",
    "            total_images += 1\n",
    "\n",
    "    return smallest_pixel, largest_pixel, channel_values\n",
    "\n",
    "\n",
    "def print_image_statistics(smallest_pixel: int,\n",
    "                           largest_pixel: int,\n",
    "                           total_images: int,\n",
    "                           channel_values: Dict\n",
    "                           )-> None:\n",
    "    \"\"\"\n",
    "    Print the image statistics.\n",
    "\n",
    "    Args:\n",
    "    - smallest_pixel (int): Smallest pixel value found in the images.\n",
    "    - largest_pixel (int): Largest pixel value found in the images.\n",
    "    - total_images (int): Total number of images processed.\n",
    "    - channel_values (Dict[str, List[Tuple[float, float]]]): Channel-wise\n",
    "    mean and standard deviation values.\n",
    "    \"\"\"\n",
    "    print(f\"Smallest pixel value: {smallest_pixel}\")\n",
    "    print(f\"Largest pixel value: {largest_pixel}\")\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "\n",
    "    if not channel_values:\n",
    "        print(\"No images were processed.\")\n",
    "    else:\n",
    "        print(\"Channel Statistics:\")\n",
    "        for channel, values in channel_values.items():\n",
    "            print(f\"Channel '{channel}':\")\n",
    "            for i, (mean, std) in enumerate(values):\n",
    "                print(f\"  Image {i+1} - Mean: {mean},\"\n",
    "                      f\" Standard Deviation: {std}\")\n",
    "\n",
    "\n",
    "def format_image_statistics(smallest_pixel: int,\n",
    "                            largest_pixel: int,\n",
    "                            total_images: int,\n",
    "                            channel_values: Dict\n",
    "                            ) -> Dict:\n",
    "    \"\"\"\n",
    "    Format the image statistics into a dictionary.\n",
    "\n",
    "    Args:\n",
    "    - smallest_pixel (int): Smallest pixel value found in the images.\n",
    "    - largest_pixel (int): Largest pixel value found in the images.\n",
    "    - total_images (int): Total number of images processed.\n",
    "    - channel_values (Dict): Channel-wise mean and standard deviation values.\n",
    "\n",
    "    Returns:\n",
    "    - image_stats (Dict): Dictionary containing image statistics.\n",
    "    \"\"\"\n",
    "    is_gray = len(channel_values) == 1 and 'R' in channel_values\n",
    "    if is_gray:\n",
    "        return {\n",
    "            'smallest_pixel_value': smallest_pixel,\n",
    "            'largest_pixel_value': largest_pixel,\n",
    "            'total_images': total_images,\n",
    "            'channel_statistics': {},\n",
    "            'channels': 1\n",
    "        }\n",
    "\n",
    "    # Calculate average and standard deviation per channel\n",
    "    channel_stats = {}\n",
    "    for channel, values in channel_values.items():\n",
    "        avg = np.mean([val[0] for val in values])\n",
    "        std_dev = np.mean([val[1] for val in values])\n",
    "        channel_stats[channel] = {'average': avg, 'std_dev': std_dev}\n",
    "\n",
    "    return {\n",
    "        'smallest_pixel_value': smallest_pixel,\n",
    "        'largest_pixel_value': largest_pixel,\n",
    "        'total_images': total_images,\n",
    "        'channel_statistics': channel_stats,\n",
    "        'channels': 3\n",
    "    }\n",
    "\n",
    "\n",
    "def image_analysis(dataframe: pd.DataFrame,\n",
    "                   path_column: str = 'path'\n",
    "                   ) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze the images in the DataFrame and extract image statistics.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing image paths.\n",
    "    - path_column (str, optional): Name of the column containing\n",
    "    image paths (default: 'path').\n",
    "\n",
    "    Returns:\n",
    "    - image_stats (Dict): Dictionary containing image statistics.\n",
    "    \"\"\"\n",
    "    smallest_pixel, largest_pixel, channel_values = (\n",
    "        calculate_image_statistics(dataframe, path_column))\n",
    "    print_image_statistics(smallest_pixel,\n",
    "                           largest_pixel,\n",
    "                           len(dataframe),\n",
    "                           channel_values)\n",
    "    image_stats = format_image_statistics(smallest_pixel,\n",
    "                                          largest_pixel,\n",
    "                                          len(dataframe),\n",
    "                                          channel_values)\n",
    "    return image_stats\n",
    "\n",
    "\n",
    "def check_images_existence(dataframe: pd.DataFrame,\n",
    "                           path_column: str = 'path'\n",
    "                           ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check the existence of image files in the specified folder path.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing image paths.\n",
    "    - path_column (str, optional): Name of the column containing\n",
    "    image paths (default: 'path').\n",
    "\n",
    "    Returns:\n",
    "    - cleaned_dataframe (pd.DataFrame): DataFrame with removed\n",
    "    rows containing non-existent image paths.\n",
    "    \"\"\"\n",
    "    cleaned_dataframe = dataframe.copy()\n",
    "    removed_images = []\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in dataframe.iterrows():\n",
    "        image_path = row[path_column]\n",
    "\n",
    "        if image_path is None or not os.path.exists(image_path):\n",
    "            removed_images.append(row)\n",
    "            cleaned_dataframe.drop(index, inplace=True)\n",
    "            print(f\"Image not found in folder: {image_path}\")\n",
    "\n",
    "    # Print removed lines\n",
    "    if removed_images:\n",
    "        print(\"Removed lines:\")\n",
    "        for row in removed_images:\n",
    "            print(row)\n",
    "\n",
    "    return cleaned_dataframe\n",
    "\n",
    "\n",
    "def analyze_image_shapes(dataframe: pd.DataFrame,\n",
    "                         min_shape: Tuple[int, int],\n",
    "                         path_column: str = 'path'\n",
    "                         ) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Analyze the shapes of images in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing image paths.\n",
    "    - min_shape (Tuple[int, int]): Minimum shape required for images.\n",
    "    - path_column (str, optional): Name of the column containing\n",
    "    image paths (default: 'path').\n",
    "\n",
    "    Returns:\n",
    "    - image_stats (Dict[str, int]): Dictionary containing image\n",
    "    shape statistics.\n",
    "    \"\"\"\n",
    "    total_images = 0\n",
    "    total_height = 0\n",
    "    total_width = 0\n",
    "    smaller_than_x_count = 0\n",
    "\n",
    "    # Iterate through each row in the dataframe\n",
    "    for _, row in dataframe.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Read the image using imageio\n",
    "            image = imageio.imread(image_path)\n",
    "            if len(image.shape) == 2:  # Check if image is grayscale\n",
    "                height, width = image.shape\n",
    "            else:  # Color image (RGB)\n",
    "                height, width, _ = image.shape\n",
    "\n",
    "            total_images += 1\n",
    "            total_height += height\n",
    "            total_width += width\n",
    "\n",
    "            # Check if the image shape is smaller than min_shape\n",
    "            if height < min_shape[0] or width < min_shape[1]:\n",
    "                smaller_than_x_count += 1\n",
    "\n",
    "    # Calculate the average shape of the images\n",
    "    average_height = total_height / total_images if total_images > 0 else 0\n",
    "    average_width = total_width / total_images if total_images > 0 else 0\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Average image shape - Height: \"\n",
    "          f\"{average_height}, Width: {average_width}\")\n",
    "\n",
    "    print(\"Number of images with shape smaller \"\n",
    "          f\"than {min_shape}: {smaller_than_x_count}\")\n",
    "\n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        'average_height': average_height,\n",
    "        'average_width': average_width,\n",
    "        'smaller_than_x_count': smaller_than_x_count\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import glob\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import PIL \n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tool_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, labels are initially considered as categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the images are organized in the folders of each label, the following flag must be True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grande Osmar, deixa a flag como True mesmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_folder_sep = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_folder_sep:\n",
    "    base_path = input(\"Qual é o caminho do dataset?\")\n",
    "    # base_path = 'C:/Users/lucas/OneDrive - unb.br/Documents/UnB/Semestres-ENE/TCC/COVID_Dataset_original'\n",
    "    results_path = input(\"Qual será o caminho para os resultados?\")\n",
    "    # results_path = f\"C:/Users/Lucas/medical_images_models/results_COVID\"\n",
    "else:\n",
    "    # base_path = 'C:/Users/lucas/OneDrive - unb.br/Documents/UnB/Semestres-ENE/TCC/The HAM10000 dataset'\n",
    "    # results_path = f\"C:/Users/Lucas/medical_images_models/results_HAM\"\n",
    "    base_path = input(\"Qual é o caminho do dataset?\")\n",
    "    results_path = input(\"Qual será o caminho para os resultados?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nv - 671\n",
      "mel - 112\n",
      "bkl - 110\n",
      "bcc - 52\n",
      "akiec - 33\n",
      "vasc - 15\n",
      "df - 12\n"
     ]
    }
   ],
   "source": [
    "if flag_folder_sep :\n",
    "    label_column = 'label'\n",
    "    train_df, test_df, val_df  = make_dataset_by_folder(base_path=base_path, label_column=label_column)\n",
    "\n",
    "else:\n",
    "    \n",
    "    path_train_df = f'{base_path}/HAM10000_metadata'\n",
    "    path_test_df = f'{base_path}/test.csv'\n",
    "    \n",
    "    path_train = f\"{base_path}/treino\"\n",
    "    path_test = f\"{base_path}/test\"\n",
    "    \n",
    "    paths_image = [path_train, path_test]\n",
    "    paths_df = [path_train_df, path_test_df]\n",
    "    label_column = 'dx'\n",
    "    \n",
    "    train_df, test_df, val_df = make_dataset_by_df(paths_image, paths_df, label_column=label_column)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = check_images_existence(train_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_analysis_train \u001b[38;5;241m=\u001b[39m \u001b[43mimage_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Codigos_VS\\medical_images_models\\tool_preprocessing.py:152\u001b[0m, in \u001b[0;36mimage_analysis\u001b[1;34m(dataframe, path_column)\u001b[0m\n\u001b[0;32m    149\u001b[0m image_path \u001b[38;5;241m=\u001b[39m row[path_column]\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image_path\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# Read the image using imageio\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# Check if the image is grayscale or RGB\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# Grayscale image\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py:265\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperhaps you mean \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpilmode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    262\u001b[0m     )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Get reader and read first\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m reader \u001b[38;5;241m=\u001b[39m read(uri, \u001b[38;5;28mformat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mget_data(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py:178\u001b[0m, in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m formats[\u001b[38;5;28mformat\u001b[39m]\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mformats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_read_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     modename \u001b[38;5;241m=\u001b[39m MODENAMES\u001b[38;5;241m.\u001b[39mget(mode, mode)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\format.py:689\u001b[0m, in \u001b[0;36mFormatManager.search_read_format\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;66;03m# Select the first that can\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m selected_formats:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcan_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    690\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# If no format could read it, it could be that file has no or\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# the wrong extension. We ask all formats again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\format.py:192\u001b[0m, in \u001b[0;36mFormat.can_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcan_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;124;03m\"\"\" can_read(request)\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    Get whether this format can read data from the specified uri.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\plugins\\pillow.py:107\u001b[0m, in \u001b[0;36mPillowFormat._can_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    105\u001b[0m factory, accept \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mOPEN[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplugin_id]\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirstbytes\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m accept(request\u001b[38;5;241m.\u001b[39mfirstbytes):\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py:442\u001b[0m, in \u001b[0;36mRequest.firstbytes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03m\"\"\" The first 256 bytes of the file. These can be used to\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03mparse the header to determine the file-format.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_firstbytes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_first_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_firstbytes\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py:451\u001b[0m, in \u001b[0;36mRequest._read_first_bytes\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# Prepare\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m         f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename):  \u001b[38;5;66;03m# A directory, e.g. for DICOM\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py:333\u001b[0m, in \u001b[0;36mRequest.get_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uri_type \u001b[38;5;241m==\u001b[39m URI_ZIPPED:\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m# Get the correct filename\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     filename, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename_zip\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_analysis_train = image_analysis(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 9010\n",
      "Number of unique labels: 7\n",
      "Label 'nv' has 6034 images.\n",
      "Label 'mel' has 1001 images.\n",
      "Label 'bkl' has 989 images.\n",
      "Label 'bcc' has 462 images.\n",
      "Label 'akiec' has 294 images.\n",
      "Label 'vasc' has 127 images.\n",
      "Label 'df' has 103 images.\n",
      "Average image shape - Height: 450.0, Width: 600.0\n",
      "Number of images with shape smaller than (800, 800): 9010\n"
     ]
    }
   ],
   "source": [
    "dict_train_qntd = get_label_counts_and_print(train_df, label_column=label_column)\n",
    "shapes_train = analyze_image_shapes(train_df, min_shape=(800, 800), path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nv': 6034,\n",
       " 'mel': 1001,\n",
       " 'bkl': 989,\n",
       " 'bcc': 462,\n",
       " 'akiec': 294,\n",
       " 'vasc': 127,\n",
       " 'df': 103}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_train_qntd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = check_images_existence(test_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest pixel value: 0\n",
      "Largest pixel value: 255\n",
      "Total images processed: 1511\n",
      "Channel Statistics:\n",
      "Channel 'R':\n",
      "  - Average: 193.96235187636344\n",
      "  - Standard Deviation: 24.606448726550262\n",
      "Channel 'G':\n",
      "  - Average: 141.7550379243572\n",
      "  - Standard Deviation: 31.9625774054364\n",
      "Channel 'B':\n",
      "  - Average: 147.87214814814814\n",
      "  - Standard Deviation: 35.78649271231254\n"
     ]
    }
   ],
   "source": [
    "image_analysis_test = image_analysis(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_qntd = get_label_counts_and_print(test_df, label_column=label_column)\n",
    "shapes_test = analyze_image_shapes(test_df, min_shape=(300, 300), path_column='path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = check_images_existence(val_df, path_column='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_analysis_val = image_analysis(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_val_qntd = get_label_counts_and_print(val_df, label_column=label_column)\n",
    "shapes_val = analyze_image_shapes(val_df, min_shape=(461, 601), path_column='path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passar de categorial para binário "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pesos para a loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorial to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = labels2dict(train_df, label_column)\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label, test_label, val_label = dflabel2number([train_df, test_df, val_df], labels_dict, label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(labels_dict) == 1:\n",
    "    weights = calculate_weights(train_df, labels_dict, dict_train_qntd)\n",
    "    weights = max(weights)\n",
    "else:\n",
    "    weights = calculate_weights(train_df, labels_dict, dict_train_qntd)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CT_Dataset(Dataset):\n",
    "    def __init__(self, img_path, img_labels, channels, img_transforms=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_labels = torch.Tensor(img_labels)\n",
    "        if channels == 1:\n",
    "            self.transforms = transforms.Compose([transforms.Grayscale(),\n",
    "                                                #   transforms.Resize((250, 250)),\n",
    "                                                  transforms.ToTensor()])\n",
    "        elif channels == 3:\n",
    "            self.transforms = transforms.Compose([#transforms.Resize((250, 250)),\n",
    "                                                  transforms.ToTensor()])\n",
    "        else:\n",
    "            self.transforms = img_transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        cur_path = self.img_path[index]\n",
    "        cur_img = PIL.Image.open(cur_path).convert('RGB')\n",
    "        cur_img = self.transforms(cur_img)\n",
    "\n",
    "        return cur_img, self.img_labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current GPU memory usage:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n",
    "print(\"Max GPU memory usage:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 124\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mean_R = image_analysis_val['channel_statistics']['R']['average']\n",
    "    mean_G = image_analysis_val['channel_statistics']['G']['average']\n",
    "    mean_B = image_analysis_val['channel_statistics']['B']['average']\n",
    "    channels = 1 if mean_R == mean_G == mean_B else 3\n",
    "    \n",
    "except KeyError:\n",
    "    channels = image_analysis_val['channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CT_Dataset(img_path=np.array(train_df['path']), img_labels=np.array(train_label), channels=channels)\n",
    "val_dataset = CT_Dataset(img_path=np.array(val_df['path']), img_labels=np.array(val_label), channels=channels)\n",
    "test_dataset = CT_Dataset(img_path=np.array(test_df['path']), img_labels=np.array(test_label), channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "Epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "# model_kernel = VGG16(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = ResNet50(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = ResNet101(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = EfficientNetB0(num_classes=len(labels_dict), input_channels=channels)\n",
    "# model_kernel = EfficientNetB4(num_classes=len(labels_dict), input_channels=channels)\n",
    "model_kernel = EfficientNetB7(num_classes=len(labels_dict), input_channels=channels)\n",
    "\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(model_kernel, device, weights, labels_dict, train_dataset, val_dataset, test_dataset, batch_size= batch_size, epochs=Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.loader()\n",
    "trainer.loss_function()\n",
    "trainer.optimizer_step()\n",
    "print(\"Training Start:\")\n",
    "for epoch in range(Epochs):\n",
    "    trainer.model.train()\n",
    "\n",
    "    trainer.train_loss = 0\n",
    "    trainer.train_acc = 0\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.validate()\n",
    "    history = trainer.loss_acc()\n",
    "\n",
    "\n",
    "    print(f\"Epoch:{epoch + 1} / {Epochs}, lr: {trainer.optimizer.param_groups[0]['lr']:.5f} train loss:{trainer.train_loss:.5f}, train acc: {trainer.train_acc:.5f}, valid loss:{trainer.val_loss:.5f}, valid acc:{trainer.val_acc:.5f}\")\n",
    "        \n",
    "    # Update the best model if validation loss is the lowest so far\n",
    "    if trainer.val_loss < trainer.best_val_loss:\n",
    "        trainer.best_val_loss = trainer.val_loss\n",
    "        trainer.best_model_state = trainer.model.state_dict()\n",
    "\n",
    "    print(f'The best val loss is {trainer.best_val_loss}.\\n')\n",
    "    \n",
    "    # Load the best model state\n",
    "    if trainer.best_model_state is not None:\n",
    "        trainer.model.load_state_dict(trainer.best_model_state)\n",
    "    model = trainer.model\n",
    "    \n",
    "trainer.test()\n",
    "metrics_df = trainer.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = trainer.metrics()\n",
    "metrics_df = metrics_df.applymap(lambda x: str(x).replace('.', ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_metrics import *                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if flag_folder_sep:\n",
    "#     results_path = f\"C:/Users/Lucas/medical_images_models/results_COVID/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}\"\n",
    "\n",
    "# else:\n",
    "#     results_path = f\"C:/Users/Lucas/medical_images_models/results_HAM/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(f\"{results_path}/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, path=results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Images - True Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_labels_dict = {value: key for key, value in labels_dict.items()}\n",
    "inverted_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_pred_true(model, test_dataset, device, inverted_labels_dict, num_images_to_plot=20, plot_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{results_path}/Model_{model.get_name()}__Epoch_{Epochs}__Batch_{batch_size}__Accuracy_{metrics_df['Accuracy'][0]}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
